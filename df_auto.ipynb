{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rCNVOpk6iFp3xglyyHzWPggaAr0INo_E",
      "authorship_tag": "ABX9TyNxs79oITBq7UzW/tk+gKUT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FauziRahmatullahSiregar/Significant-Weather/blob/main/df_auto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "b31YLQ0w00yi"
      },
      "outputs": [],
      "source": [
        "!pip install -q metpy\n",
        "!pip install -q ecmwflibs\n",
        "!pip install -q eccodes\n",
        "!pip uninstall -y -q xarray\n",
        "!pip install -q xarray cfgrib\n",
        "\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from metpy.units import units\n",
        "import metpy.calc as mpcalc\n",
        "import pickle\n",
        "import requests\n",
        "\n",
        "def calculate_tsi(dataset):\n",
        "    '''\n",
        "    Calculate the Thunderstorm Index (TSI) based on the TTI, KI, and the relative humidity\n",
        "    :param dataset: xarray dataset with temperature and relative humidity\n",
        "    :return: xarray dataset with the TSI\n",
        "    '''\n",
        "\n",
        "    # Create a grid of zeros\n",
        "    grid = np.zeros((dataset.sizes['latitude'], dataset.sizes['longitude']))\n",
        "    dataset = dataset.metpy.quantify()\n",
        "\n",
        "    # Calculate Dewpoint\n",
        "    dew = mpcalc.dewpoint_from_relative_humidity(dataset['t'], dataset['r']).metpy.dequantify()\n",
        "    dew_850 = dew.sel(isobaricInhPa=850)\n",
        "    dew_700 = dew.sel(isobaricInhPa=700)\n",
        "\n",
        "    temp_850 = dataset['t'].sel(isobaricInhPa=850).metpy.convert_units('degC').metpy.dequantify()\n",
        "    temp_700 = dataset['t'].sel(isobaricInhPa=700).metpy.convert_units('degC').metpy.dequantify()\n",
        "    temp_500 = dataset['t'].sel(isobaricInhPa=500).metpy.convert_units('degC').metpy.dequantify()\n",
        "    r_850 = dataset['r'].sel(isobaricInhPa=850).metpy.dequantify()\n",
        "    r_700 = dataset['r'].sel(isobaricInhPa=700).metpy.dequantify()\n",
        "    r_500 = dataset['r'].sel(isobaricInhPa=500).metpy.dequantify()\n",
        "\n",
        "    TTI = temp_850 + dew_850 - (2 * temp_500)\n",
        "    KI = (temp_850 - temp_500) + dew_850 - (temp_700 - dew_700)\n",
        "\n",
        "    grid[(r_500 > 90) & (TTI > 44) & (KI > 25)] = 1\n",
        "\n",
        "    tsi = xr.DataArray(grid, coords=[dataset['latitude'], dataset['longitude']], dims=['latitude', 'longitude'])\n",
        "    return tsi\n",
        "\n",
        "\n",
        "def calculate_ww(tp, vis, tcc, tsi):\n",
        "    '''\n",
        "    Calculate the Weather Category (WW) based on the TP, VIS, TCC, and TSI\n",
        "    :param tp: xarray dataset with total precipitation\n",
        "    :param vis: xarray dataset with visibility\n",
        "    :param tcc: xarray dataset with total cloud cover\n",
        "    :param tsi: xarray dataset with thunderstorm index\n",
        "    :return: xarray dataset with the WW\n",
        "    '''\n",
        "    # Ensure all inputs are DataArrays\n",
        "    tp = (tp.to_array() if isinstance(tp, xr.Dataset) else tp).squeeze()\n",
        "    vis = (vis.to_array() if isinstance(vis, xr.Dataset) else vis).squeeze()\n",
        "    tcc = (tcc.to_array() if isinstance(tcc, xr.Dataset) else tcc).squeeze()\n",
        "    tsi = (tsi.to_array() if isinstance(tsi, xr.Dataset) else tsi).squeeze()\n",
        "\n",
        "    # Create a grid of zeros\n",
        "    grid = np.zeros((tp.sizes['latitude'], tp.sizes['longitude']))\n",
        "\n",
        "    grid[(tsi == 1) & (tp <= 1)] = 17\n",
        "    grid[(tsi == 1) & (tp > 1)] = 95\n",
        "    grid[(tsi == 0) & (tp > 10)] = 65\n",
        "    grid[(tsi == 0) & (tp > 5) & (tp <= 10)] = 63\n",
        "    grid[(tsi == 0) & (tp > 1) & (tp <= 5)] = 61\n",
        "    grid[(tsi == 0) & (tp <= 1) & (vis < 1000)] = 45\n",
        "    grid[(tsi == 0) & (tp <= 1) & (vis <= 5000) & (vis >= 1000)] = 10\n",
        "    grid[(tsi == 0) & (tp <= 1) & (vis > 5000) & (tcc < 10)] = 0\n",
        "    grid[(tsi == 0) & (tp <= 1) & (vis > 5000) & (tcc < 60) & (tcc >= 10)] = 1\n",
        "    grid[(tsi == 0) & (tp <= 1) & (vis > 5000) & (tcc < 90) & (tcc >= 60)] = 2\n",
        "    grid[(tsi == 0) & (tp <= 1) & (vis > 5000) & (tcc > 90)] = 3\n",
        "\n",
        "    ww = xr.DataArray(grid, coords=[tp['latitude'], tp['longitude']], dims=['latitude', 'longitude'])\n",
        "    return ww\n",
        "\n",
        "def load_data(model):\n",
        "    # Load data for TSI\n",
        "    ds_tsi = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'isobaricInhPa'}})[['t','r']].sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')\n",
        "    if model == 'GFS':\n",
        "        # Load data for TP\n",
        "        ds_tp1 = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'accum','typeOfLevel': 'surface','shortName':'tp'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['tp']\n",
        "        ds_tp2 = xr.load_dataset(filename_2, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'accum','typeOfLevel': 'surface','shortName':'tp'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['tp']\n",
        "        ds_tp = ds_tp2 - ds_tp1\n",
        "        # Load data for Vis\n",
        "        ds_vis = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'instant','typeOfLevel': 'surface','shortName':'vis'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['vis']\n",
        "\n",
        "        #Total Cloud Cover\n",
        "        ds_tcc = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'instant','typeOfLevel': 'atmosphere', 'shortName':'tcc'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['tcc']\n",
        "\n",
        "        # Load additional data\n",
        "        ds_surface = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'heightAboveGround','level':2.0}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')\n",
        "        ds_wind = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'heightAboveGround','level':10.0}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')\n",
        "        r2 = ds_surface['r2']\n",
        "\n",
        "    elif model == 'IFS':\n",
        "        # Load data for TP\n",
        "        ds_tp1 = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'surface','shortName':'tp'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['tp']\n",
        "        ds_tp2 = xr.load_dataset(filename_2, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'surface','shortName':'tp'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['tp']\n",
        "        ds_tp = ds_tp2 - ds_tp1\n",
        "\n",
        "        # Load data for Vis\n",
        "        ds_vis = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'instant','typeOfLevel': 'surface','shortName':'vis'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['vis']\n",
        "\n",
        "        #Total Cloud Cover\n",
        "        ds_tcc = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'instant','typeOfLevel': 'surface','shortName':'tcc'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['tcc']\n",
        "\n",
        "        # Load additional data\n",
        "        ds_surface = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'surface','edition':1}})[['t2m','d2m']].sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')\n",
        "        r2 = mpcalc.relative_humidity_from_dewpoint(ds_surface['t2m'], ds_surface['d2m']).metpy.dequantify()\n",
        "        ds_wind = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'surface','edition':1}})[['u10','v10']].sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')\n",
        "\n",
        "    else:\n",
        "        # Load data for TP\n",
        "        ds_tp1 = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'accum','typeOfLevel': 'surface'}})[['tirf']].sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['tirf']\n",
        "        ds_tp2 = xr.load_dataset(filename_2, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'accum','typeOfLevel': 'surface'}})[['tirf']].sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['tirf']\n",
        "        ds_tp = ds_tp2 - ds_tp1\n",
        "\n",
        "        # Load data for Vis\n",
        "        ds_vis = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'stepType': 'min','typeOfLevel': 'surface'}})[['unknown']].sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['unknown']\n",
        "\n",
        "        #Total Cloud Cover\n",
        "        ds_tcc = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'surface', 'stepType': 'instant', 'shortName':'unknown'}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')['unknown']\n",
        "\n",
        "        # Load additional data\n",
        "        ds_surface = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'heightAboveGround','level':2.0}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')\n",
        "        ds_wind = xr.load_dataset(filename_1, engine='cfgrib', backend_kwargs={'filter_by_keys': {'typeOfLevel': 'heightAboveGround','level':10.0}}).sel(latitude=lats, longitude=lons).interp(latitude=df_lats, longitude=df_lons, method='linear')\n",
        "        r2 = ds_surface['r2']\n",
        "\n",
        "\n",
        "    tsi = calculate_tsi(ds_tsi)\n",
        "    ww = calculate_ww(ds_tp, ds_vis, ds_tcc, tsi)\n",
        "    coords = ds_tp.coords\n",
        "\n",
        "    ds_fc = xr.Dataset(\n",
        "          {\n",
        "          'tp': (['latitude','longitude'],ds_tp.values),\n",
        "          'tsi': (['latitude','longitude'],tsi.values),\n",
        "          't2m': (['latitude','longitude'], ds_surface['t2m'].values),\n",
        "          'tcc': (['latitude','longitude'], ds_tcc.values),\n",
        "          'vis': (['latitude','longitude'], ds_vis.values),\n",
        "          'r2': (['latitude','longitude'], r2.values),\n",
        "          },\n",
        "          coords=coords)\n",
        "\n",
        "    ds_fc_wind = xr.Dataset(\n",
        "          {\n",
        "          'u10': (['latitude','longitude'],ds_wind['u10'].values),\n",
        "\n",
        "          'v10': (['latitude','longitude'],ds_wind['v10'].values),\n",
        "          },\n",
        "          coords=coords)\n",
        "\n",
        "    ds_af = xr.Dataset(\n",
        "          {\n",
        "          'ww': (['latitude','longitude'],ww.values),\n",
        "          },\n",
        "          coords=coords)\n",
        "\n",
        "    # Save the dataset\n",
        "    ds_complete = xr.merge([ds_fc, ds_fc_wind, ds_af],compat='override')\n",
        "    ds_complete.attrs = {\n",
        "        'GRIB_edition': 2,\n",
        "        'GRIB_centre': 'wiix',\n",
        "        'GRIB_centreDescription': 'Indonesia Meteorological Climatological and Geophysical Agency - BMKG',\n",
        "        'GRIB_subCentre': 0,\n",
        "        'Conventions': 'CF-1.7',\n",
        "        'institution': 'Indonesia Meteorological Climatological and Geophysical Agency - BMKG',\n",
        "      }\n",
        "\n",
        "    ds_complete.to_netcdf(f'df_auto_{model}_test.nc')\n",
        "    return ds_complete"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "\n",
        "#If the data already exists\n",
        "#filename_1 = '/content/drive/MyDrive/0001/A1D07251200072512011_R20240725120000_20240725120000_20240725120000.grib'\n",
        "#filename_2 = '/content/drive/MyDrive/0001/A1D07251200072512011_R20240725120000_20240725120000_20240725120000.grib'\n",
        "\n",
        "#'''If the data is downloaded first\n",
        "\n",
        "!wget https://nomads.ncep.noaa.gov/pub/data/nccf/com/gfs/prod/gfs.20240801/00/atmos/gfs.t00z.pgrb2.0p25.f003\n",
        "filename_1 = 'gfs.t00z.pgrb2.0p25.f003'\n",
        "\n",
        "!wget https://nomads.ncep.noaa.gov/pub/data/nccf/com/gfs/prod/gfs.20240801/00/atmos/gfs.t00z.pgrb2.0p25.f006\n",
        "filename_2 = 'gfs.t00z.pgrb2.0p25.f006'\n",
        "\n",
        "#'''\n",
        "# Domain slice\n",
        "lats = slice (9, -13)\n",
        "lons = slice (90, 143)\n",
        "\n",
        "# Load lats lons from the harmonization\n",
        "with open('/content/drive/MyDrive/0001/df_latitudes.pkl', 'rb') as f:\n",
        "    df_lats = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/0001/df_longitudes.pkl', 'rb') as f:\n",
        "    df_lons = pickle.load(f)\n",
        "\n",
        "ds_complete = load_data('GFS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9m2ja3QssgwV",
        "outputId": "87d44957-a987-46a8-f131-e8d10b287be8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-02 01:46:31--  https://nomads.ncep.noaa.gov/pub/data/nccf/com/gfs/prod/gfs.20240801/00/atmos/gfs.t00z.pgrb2.0p25.f003\n",
            "Resolving nomads.ncep.noaa.gov (nomads.ncep.noaa.gov)... 23.210.215.16, 23.210.215.43, 2600:1417:76::17d2:d710, ...\n",
            "Connecting to nomads.ncep.noaa.gov (nomads.ncep.noaa.gov)|23.210.215.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 538373465 (513M)\n",
            "Saving to: ‘gfs.t00z.pgrb2.0p25.f003.3’\n",
            "\n",
            "gfs.t00z.pgrb2.0p25 100%[===================>] 513.43M   122MB/s    in 3.7s    \n",
            "\n",
            "2024-08-02 01:46:34 (138 MB/s) - ‘gfs.t00z.pgrb2.0p25.f003.3’ saved [538373465/538373465]\n",
            "\n",
            "--2024-08-02 01:46:35--  https://nomads.ncep.noaa.gov/pub/data/nccf/com/gfs/prod/gfs.20240801/00/atmos/gfs.t00z.pgrb2.0p25.f006\n",
            "Resolving nomads.ncep.noaa.gov (nomads.ncep.noaa.gov)... 23.210.215.16, 23.210.215.43, 2600:1417:76::17d2:d710, ...\n",
            "Connecting to nomads.ncep.noaa.gov (nomads.ncep.noaa.gov)|23.210.215.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 542166179 (517M)\n",
            "Saving to: ‘gfs.t00z.pgrb2.0p25.f006.3’\n",
            "\n",
            "gfs.t00z.pgrb2.0p25 100%[===================>] 517.05M  44.9MB/s    in 7.4s    \n",
            "\n",
            "2024-08-02 01:46:42 (69.5 MB/s) - ‘gfs.t00z.pgrb2.0p25.f006.3’ saved [542166179/542166179]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:cfgrib.dataset:skipping variable: paramId==228164 shortName='tcc'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   70.,   50.,   40.,   30.,   20.,   15.,\n",
            "         10.,    7.,    5.,    3.,    2.,    1.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   50.]))\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==260018 shortName='clwmr'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   70.,   50.,   40.,   30.,   20.,   15.,\n",
            "         10.,    7.,    5.,    3.,    2.,    1.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   50.]))\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==260019 shortName='icmr'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   70.,   50.,   40.,   30.,   20.,   15.,\n",
            "         10.,    7.,    5.,    3.,    2.,    1.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   50.]))\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==260020 shortName='rwmr'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   70.,   50.,   40.,   30.,   20.,   15.,\n",
            "         10.,    7.,    5.,    3.,    2.,    1.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   50.]))\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==260021 shortName='snmr'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   70.,   50.,   40.,   30.,   20.,   15.,\n",
            "         10.,    7.,    5.,    3.,    2.,    1.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   50.]))\n",
            "ERROR:cfgrib.dataset:skipping variable: paramId==260028 shortName='grle'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 721, in build_dataset_components\n",
            "    dict_merge(variables, coord_vars)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/cfgrib/dataset.py\", line 639, in dict_merge\n",
            "    raise DatasetBuildError(\n",
            "cfgrib.dataset.DatasetBuildError: key present and new value is different: key='isobaricInhPa' value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   70.,   50.,   40.,   30.,   20.,   15.,\n",
            "         10.,    7.,    5.,    3.,    2.,    1.])) new_value=Variable(dimensions=('isobaricInhPa',), data=array([1000.,  975.,  950.,  925.,  900.,  850.,  800.,  750.,  700.,\n",
            "        650.,  600.,  550.,  500.,  450.,  400.,  350.,  300.,  250.,\n",
            "        200.,  150.,  100.,   50.]))\n",
            "/usr/local/lib/python3.10/dist-packages/metpy/calc/thermo.py:1396: RuntimeWarning: divide by zero encountered in log\n",
            "  val = np.log(vapor_pressure / mpconsts.nounit.sat_pressure_0c)\n",
            "/usr/local/lib/python3.10/dist-packages/metpy/calc/thermo.py:1397: RuntimeWarning: invalid value encountered in divide\n",
            "  return mpconsts.nounit.zero_degc + 243.5 * val / (17.67 - val)\n"
          ]
        }
      ]
    }
  ]
}